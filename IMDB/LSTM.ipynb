{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(r\"train\\labeledTrainData.tsv\",sep='\\t')\n",
    "test = pd.read_csv(r\"test\\testData.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS=20000\n",
    "tokenizer = Tokenizer(MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "texts = np.concatenate([train.review.values,test.review.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 124252 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = data[:25000]\n",
    "train_l = train.sentiment.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = data[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(25000,2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_valid = train_x[idx]\n",
    "l_valid = train_l[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "allind = np.arange(len(train_x))\n",
    "idx2 = np.setdiff1d(allind,idx)\n",
    "x_train = train_x[idx2]\n",
    "l_train = train_l[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "embeddings_index = {}\n",
    "GLOVE_DIR = r'..\\Glove\\glove.6B'\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'),encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    #print(values)\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 100)          12425300  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 300)               481200    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 12,906,801\n",
      "Trainable params: 481,501\n",
      "Non-trainable params: 12,425,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Embedding,Dense,Dropout\n",
    "\n",
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False))\n",
    "model.add(LSTM(300,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22626 samples, validate on 2500 samples\n",
      "Epoch 1/3\n",
      "22626/22626 [==============================] - 1385s - loss: 0.6304 - acc: 0.6399 - val_loss: 0.5901 - val_acc: 0.6696\n",
      "Epoch 2/3\n",
      "22626/22626 [==============================] - 1463s - loss: 0.5479 - acc: 0.7247 - val_loss: 0.4081 - val_acc: 0.8212\n",
      "Epoch 3/3\n",
      "22626/22626 [==============================] - 1456s - loss: 0.4228 - acc: 0.8084 - val_loss: 0.3351 - val_acc: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25226ddf748>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(batch_size=128,epochs=3,validation_data=(x_valid,l_valid),x=x_train,y=l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'lstm_3/kernel:0' shape=(100, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'lstm_3/recurrent_kernel:0' shape=(300, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'lstm_3/bias:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(300, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'embedding_3/embeddings:0' shape=(124253, 100) dtype=float32_ref>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2322"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(list(map(len,sequences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test_x,batch_size=128)\n",
    "ans=np.rint(predicted).astype(np.int32)\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "df = pd.DataFrame()\n",
    "df['id'] = test.id\n",
    "df['sentiment'] = ans\n",
    "df.to_csv('submit'+str(now.hour)+str(now.minute)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   21,    1, 1598],\n",
       "       [   0,    0,    0, ...,   26,   92, 5686],\n",
       "       [   0,    0,    0, ..., 1305,    4, 5344],\n",
       "       ..., \n",
       "       [   0,    0,    0, ...,  289,   64,  566],\n",
       "       [   0,    0,    0, ...,   22,  112, 9811],\n",
       "       [   0,    0,    0, ...,    5,   12,   27]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
